# Implementation Plan: Memoria Performance Optimization

**Branch**: `002-memoria-performance` | **Date**: 2026-01-31 | **Spec**: [spec.md](./spec.md)
**Input**: Feature specification from `/specs/002-memoria-performance/spec.md`

## Summary

Optimize memoria RAG search and indexing to fix two critical performance issues:
1. **Search returns only 1 result** despite 2000+ document collection (regressed after database growth)
2. **Indexing operations timeout** with large document collections

**Technical Approach** (from research):
- Issue 1: Investigate why hybrid_weight=0.95 fix (spec 001) no longer effective at scale
- Issue 2: Implement batch embedding API to replace sequential processing (20-30× speedup expected)

## Technical Context

**Language/Version**: Python 3.11+
**Primary Dependencies**: ChromaDB 0.4.x, sentence-transformers (all-MiniLM-L6-v2), langchain
**Storage**: ChromaDB Docker (localhost:8001), ChromaDB data persistence via Docker volumes
**Testing**: pytest (existing test suite), custom diagnostic scripts (specs/001-chroma-search-fix/diagnostics/)
**Target Platform**: macOS/Linux (local development and production)
**Project Type**: Single project (RAG library with skill interface)
**Performance Goals**:
- Search: <2s response time for 90% of queries against 2000+ docs
- Indexing: 20+ docs/minute throughput, no timeouts for 100-doc batches
**Constraints**:
- No architecture changes (v3.0 adapter pattern must remain intact)
- Backward compatibility required (search_knowledge() API unchanged)
- Memory: <2GB during peak indexing operations
**Scale/Scope**: 2000+ documents currently, targeting 10,000+ documents

## Constitution Check

**Status**: ⚠️ Constitution not yet defined for memoria project

**Action Required**: Create project constitution documenting:
- Clean architecture principles (adapters, domain, application layers)
- Immutable domain entities pattern (frozen dataclasses)
- Adapter interface contracts
- Performance testing requirements
- Backward compatibility policy

**Gate**: Constitution creation is first task before implementation begins

## Project Structure

### Documentation (this feature)

```text
specs/002-memoria-performance/
├── plan.md              # This file
├── research.md          # Phase 0 complete - performance investigation
├── data-model.md        # Phase 1 - performance metrics and batch entities
├── quickstart.md        # Phase 1 - validation and testing procedures
└── tasks.md             # Phase 2 - generated by /speckit.tasks
```

### Source Code (existing memoria structure)

```text
memoria/
├── adapters/
│   ├── chromadb/
│   │   └── chromadb_adapter.py        # Batch operations, timeout config
│   ├── search/
│   │   └── search_engine_adapter.py   # Hybrid search, result ranking
│   ├── sentence_transformers/
│   │   └── sentence_transformer_adapter.py  # NEW: batch embedding API
│   └── document_processor/
│       └── document_processor_adapter.py    # Chunking strategy
├── domain/
│   └── entities.py                    # Document, SearchResult, Embedding
├── application/
│   └── (future: orchestration layer)
├── compatibility/
│   └── raggy_facade.py                # Legacy compatibility
└── skill_helpers.py                   # PUBLIC API: search_knowledge(), index_documents()

tests/
├── integration/
│   └── test_search_quality.py         # Existing from spec 001
├── acceptance/
│   └── test_search_acceptance.py      # Existing from spec 001
└── performance/                       # NEW: performance regression tests
    ├── test_indexing_performance.py
    └── test_query_performance.py

specs/001-chroma-search-fix/diagnostics/  # Reuse existing diagnostic tools
├── validate_fix.py                    # Search quality validation
├── benchmark_performance.py           # Query performance baseline
└── search_debugger.py                 # Interactive search debugging
```

**Structure Decision**: Memoria uses clean architecture (onion model) with strict layer separation. All performance optimizations will be implemented in adapters layer (sentence_transformers, chromadb), with skill_helpers.py as orchestration. No domain or application layer changes needed.

## Complexity Tracking

**No constitution violations detected.** All proposed changes respect existing architecture:
- Batch embedding API: New adapter method (SentenceTransformerAdapter)
- Progressive batching: Orchestration logic in skill_helpers.py (already owns indexing flow)
- Timeout configuration: Adapter constructor parameter (ChromaDBAdapter)

## Phase 0: Research & Investigation ✅ COMPLETE

**Output**: [research.md](./research.md)

**Key Findings**:
1. **Issue 1 (Single Result)**: Not fixed by spec 001 as initially thought - regressed with large database
2. **Issue 2 (Indexing Timeout)**: Confirmed root cause - sequential embedding generation bottleneck
3. **Solution Path**: Batch embedding API + progressive batching for 20-30× speedup

## Phase 1: Design & Contracts

### Tasks

1. **Create Project Constitution** - Document memoria architecture principles
2. **Design Batch Embedding API** - SentenceTransformerAdapter.embed_texts_batch()
3. **Design Progressive Batching** - Commit to ChromaDB every N chunks
4. **Define Performance Metrics** - Baseline vs target metrics
5. **Create Validation Scripts** - Performance regression tests

### Outputs

- **data-model.md**: BatchEmbeddingRequest, ProgressTracker, PerformanceMetrics entities
- **quickstart.md**: How to run performance tests, validate fixes
- **constitution.md**: Memoria architecture and design principles

## Phase 2: Task Generation

Run `/speckit.tasks` to generate implementation tasks including:
- Constitution documentation
- Investigation tasks (collect current state data)
- Stop cloud supervisor worker task
- Interactive planning session preparation
- Batch embedding API implementation
- Progressive batching implementation
- Performance validation
- Backward compatibility verification

## Success Criteria Mapping

From spec.md Success Criteria:

- **SC-001** (90% queries return 5+ results): Validate with specs/001/diagnostics/validate_fix.py
- **SC-002** (Confidence score range 0.3+): Measure with search_debugger.py
- **SC-003** (0% indexing timeout rate): Performance test with 100-doc batch
- **SC-004** (90% queries <2s): Benchmark with benchmark_performance.py
- **SC-005** (20+ docs/minute throughput): Measure indexing performance
- **SC-006** (Zero breaking changes): Run existing test suite
- **SC-007** (Memory <2GB peak): Profile with memory_profiler

## Dependencies & Risks

**Dependencies**:
- Spec 001 diagnostic tools (reuse for validation)
- ChromaDB Docker container must be running
- Cloud supervisor worker must be stopped during testing (to avoid interference)

**Risks**:
- Issue 1 root cause may differ from spec 001 (requires investigation)
- Batch embedding API may not be available in sentence-transformers (fallback: manual batching)
- Memory usage may increase with batching (requires progressive commits)

**Mitigation**:
- Create investigation tasks to collect current state before implementing
- Use constitution to document constraints and design decisions
- Interactive planning session after investigation to adjust approach
